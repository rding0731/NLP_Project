{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"~/Downloads/Consumer_Complaints.csv\")\n",
    "new_Categoies = pd.read_excel('C:/Users/ruonan.ding/Desktop/workingfile.xlsx',  encoding=\"cp1252\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1056830, 18) Index(['Date received', 'Product', 'Sub-product', 'Issue', 'Sub-issue',\n",
      "       'Consumer complaint narrative', 'Company public response', 'Company',\n",
      "       'State', 'ZIP code', 'Tags', 'Consumer consent provided?',\n",
      "       'Submitted via', 'Date sent to company', 'Company response to consumer',\n",
      "       'Timely response?', 'Consumer disputed?', 'Complaint ID'],\n",
      "      dtype='object')\n",
      "[1056830, 1056830, 1056830, 1056830, 1056830, 1056830, 1056830, 1056830, 1056830, 1056830, 1056830, 1056830, 1056830, 1056830, 1056830, 1056830, 1056830, 1056830]\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, data.columns)\n",
    "print([data[i].isnull().count() for i in data.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292602, 18) (191488, 18)\n"
     ]
    }
   ],
   "source": [
    "with_data = data[data['Consumer complaint narrative'].isnull() == False]\n",
    "print(with_data.shape, with_data[with_data['Sub-issue'].isnull() == False].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final = with_data.merge(new_Categoies, on = ['Issue', 'Sub-issue'], how = 'inner').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with_data[['Complaint ID', 'Product']].groupby('Product').count()\n",
    "#with_data[['Complaint ID', 'Issue', 'Sub-issue']].groupby(['Issue', 'Sub-issue']).count().to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_lista = [1, 4, 5, 6]\n",
    "example_listb = [2, 3, 7, 11]\n",
    "\n",
    "def merge(lista, listb):\n",
    "    if len(lista) == 0 or len(listb) == 0:\n",
    "        return []\n",
    "    \n",
    "    answer = []\n",
    "    for i in range(0, len(lista)):\n",
    "        for j in range(0, len(listb)):\n",
    "            print(i , j)\n",
    "            print(answer)\n",
    "            print(lista[i], listb[j])\n",
    "            if lista[i] < listb[j]:\n",
    "                answer.append(lista[i])\n",
    "                i += 1\n",
    "                \n",
    "            elif lista[i] == listb[j]:\n",
    "                answer.append(lista[i])\n",
    "                i += 1\n",
    "                j += 1\n",
    "            else:\n",
    "                answer.append(listb[j])\n",
    "                j += 1\n",
    "    return answer\n",
    "            \n",
    "\n",
    "print merge(example_lista, example_listb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Issues = []\n",
    "for rows in with_data['Consumer complaint narrative']:\n",
    "    a = str(rows)\n",
    "    Issues.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'email_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8065e9919f48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mupper_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mupper_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0memail_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CapitalWords'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0memail_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUBJECT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcapital_words_extraction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0memail_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'UpperWords'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0memail_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUBJECT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupper_words_extraction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mUpperWords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'email_df' is not defined"
     ]
    }
   ],
   "source": [
    "def capital_words_extractioncapital_ (string):\n",
    "    words=string.split(' ')\n",
    "    capital_words=[]\n",
    "    pattern=re.compile('([A-Z]+)()')\n",
    "    for word in words:\n",
    "        result=re.findall(pattern,word)\n",
    "        if(len(result)>0):\n",
    "            capital_words.append(word)\n",
    "    return capital_words\n",
    "def upper_words_extraction(string):\n",
    "    words=string.split(' ')\n",
    "    upper_words=[]\n",
    "    pattern=re.compile('[A-Za-z]+')\n",
    "    for word in words:\n",
    "        if(word.upper()==word):\n",
    "            result=re.findall(pattern,word)\n",
    "            if((len(result)>0) & (len(word)>1)):\n",
    "                upper_words.append(word)\n",
    "    return upper_words\n",
    "email_df['CapitalWords']=email_df.SUBJECT.apply(capital_words_extraction)\n",
    "email_df['UpperWords']=email_df.SUBJECT.apply(upper_words_extraction)\n",
    "UpperWords=[]\n",
    "for x in email_df.UpperWords:\n",
    "    if(len(x)>0):\n",
    "        UpperWords.append(x)\n",
    "UpperWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_all(text, dic):\n",
    "    '''\n",
    "    Input: String and A {word: replacement} dictionary\n",
    "    Output: String\n",
    "    '''\n",
    "    for i, j in dic.items():\n",
    "        text = text.lower().replace(i, j)\n",
    "    return text\n",
    "\n",
    "\n",
    "def decontracted(phrase):\n",
    "    '''\n",
    "    This is to expand contractions\n",
    "    Input : String\n",
    "    Output: String\n",
    "    '''\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    \n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    \n",
    "    # this is to get rid of the '\\\\&quote' or anything similar to that. \n",
    "    phrase = re.sub(r\"\\\\\\\\(.*?)\", \" \", phrase)\n",
    "    phrase = re.sub(r\"\\\\(.*?)\\;\",  \"\", phrase)\n",
    "\n",
    "    return phrase\n",
    "\n",
    "## remove numbers and email address\n",
    "def word_digit_extract(phrase):\n",
    "    '''\n",
    "    Input: String\n",
    "    Output: A list of digits\n",
    "    Usage: This is to remove for modeling purpose\n",
    "    '''\n",
    "    phrase = re.sub('\\S*@\\S*\\s?', '', phrase)\n",
    "    phrase = re.sub(\"\\S*\\d\\S*\", '', phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Print' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-31caf1083cad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mIssue_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_digit_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mPrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIssue_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Print' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "replaces_list = {\"cust \": \"customer \", \"\\n\" : \"\", \"acct \" : \"account \", \"custoemr\" : \"customer\", \n",
    "                 \"stat \": \"status \", 'cst ' : 'customer '}\n",
    "\n",
    "# Step 1: decontracted the sentence\n",
    "Issue_0 = []\n",
    "for i in Issues:\n",
    "        Issue_0.append(decontracted(i))\n",
    "\n",
    "# Step 2: Replace the words in the replace_list in Issue_0.\n",
    "Issue_1 = []\n",
    "for i in range(0, len(Issue_0)):   \n",
    "    Issue_1.append(replace_all(Issue_0[i].lower(), replaces_list))\n",
    "\n",
    "# Step3: Get rid of the numbers and email\n",
    "Issue_2 = []\n",
    "for i in Issue_1:\n",
    "    Issue_2.append(word_digit_extract(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i have outdated information on my credit report that i have previously disputed that has yet to be removed this information is more then seven years old and does not meet credit reporting requirements', 'i purchased a new car on xxxx xxxx. the car dealer called citizens bank to get a  day payoff on my loan, good till xxxx xxxx. the dealer sent the check the next day. when i balanced my checkbook on xxxx xxxx. i noticed that citizens bank had taken the automatic payment out of my checking account at xxxx xxxx xxxx bank. i called citizens and they stated that they did not close the loan until xxxx xxxx. ( stating that they did not receive the check until xxxx. xxxx. ). i told them that i did not believe that the check took that long to arrive. xxxx told me a check was issued to me for the amount overpaid, they deducted additional interest. today ( xxxx xxxx, ) i called citizens bank again and talked to a supervisor named xxxx, because on xxxx xxxx. i received a letter that the loan had been paid in full ( dated xxxx, xxxx ) but no refund check was included. xxxx stated that they hold any over payment for  business days after the loan was satisfied and that my check would be mailed out on wed. the xx/xx/xxxx.. i questioned her about the delay in posting the dealer payment and she first stated that sometimes it takes  or  business days to post, then she said they did not receive the check till xxxx xxxx i again told her that i did not believe this and asked where is my money. she then stated that they hold the over payment for  business days. i asked her why, and she simply said that is their policy. i asked her if i would receive interest on my money and she stated no. i believe that citizens bank is deliberately delaying the posting of payment and the return of consumer  is money to make additional interest for the bank. if this is not illegal it should be, it does hurt the consumer and is not ethical. my amount of money lost is minimal but if they are doing this on thousands of car loans a month, then the additional interest earned for them could be staggering. i still have another car loan from citizens bank and i am afraid when i trade that car in another year i will run into the same problem again.', 'an account on my credit report has a mistaken date. i mailed in a debt validation letter to allow xxxx to correct the information. i received a letter in the mail, stating that experian received my correspondence and found it to be \" suspicious \\'\\' and that \" i did  not write it \\'\\'. experian  is letter is worded to imply that i am incapable of writing my own letter. i was deeply offended by this implication. i called experian to figure out why my letter was so suspicious. i spoke to a representative who was incredibly unhelpful, she did not effectively answer any questions i asked of her, and she kept ignoring what i was saying regarding the offensive letter and my dispute process. i feel the representative did what she wanted to do, and i am not satisfied. it is still not clear to me why i received this letter. i typed this letter, i signed this letter, and i paid to mail this letter, yet experian willfully disregarded my lawful request. i am disgusted with this entire situation, and i would like for my dispute to be handled appropriately, and i would like for an experian representative to contact me and give me a real explanation for this letter.', 'this company refuses to provide me verification and validation of debt per my right under the fdcpa. i do not believe this debt is mine.']\n"
     ]
    }
   ],
   "source": [
    "print(Issue_2[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Spelling Correction\n",
    "%run AutoCorrection.py\n",
    "Corrected_Spelling = []\n",
    "for entry in Issue_text:\n",
    "    empty = []\n",
    "    for word in entry.split(\" \"):\n",
    "        corrected_word = best_word(i, True)\n",
    "        if corrected_word is not None:\n",
    "            empty.append(best_word(word)[0])\n",
    "\n",
    "# Portter\n",
    "%run CustomerizedStemming.py\n",
    "Port = PorterStemmer()\n",
    "\n",
    "Stemmed_issues = []\n",
    "for entry in Issue_text:\n",
    "    empty = []\n",
    "    for word in entry.split(\" \"):\n",
    "         empty.append(Port.stem(word))\n",
    "    Stemmed_issues.append(\" \".join(empty))\n",
    "        else:\n",
    "            empty.append(word)\n",
    "    Corrected_Spelling.append(\" \".join(empty))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#TDIDF\n",
    "#Try both Single Gram and By_Gram\n",
    "tdidf_vectorizer = TfidfVectorizer(analyzer = 'word', max_df = 0.95, min_df = 0.001, stop_words = 'english',\n",
    "                                   use_idf = True, ngram_range = (1,2))\n",
    "\n",
    "%time \n",
    "X = tdidf_vectorizer.fit_transform(Stemmed_issues)\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "\n",
    "## Pick the number of clusters\n",
    "\n",
    "k_range = [100, 150, 200, 300, 400, 500]\n",
    "\n",
    "k_mean_Var = [MiniBatchKMeans(n_clusters = k, init_size = 30000, batch_size = 10000).fit(X_lsa_matrix) for k in k_range]\n",
    "\n",
    "centroids = [X.cluster_centers_ for X in k_mean_Var]\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "\n",
    "k_cosine = [cdist(X_lsa_matrix[:1000, ], cent, 'cosine') for cent in centroids]\n",
    "dist =[np.min(ke, axis = 1) for ke in k_cosine]\n",
    "\n",
    "wcss = [sum(d**2)/1000 for d in dist]\n",
    "\n",
    "\n",
    "\n",
    "num_cluster = 50\n",
    "\n",
    "km = MiniBatchKMeans(n_clusters = num_cluster, init = 'k-means++', n_init = 5, \n",
    "                     init_size = 300000, batch_size = 100000, reassignment_ratio = 0.1, \n",
    "                     random_state = 30)\n",
    "\n",
    "km.fit(X)\n",
    "\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "print (\"Silhouette coefficient: %0.3f\" % metrics.silhouette_score(X, km.labels_, metric = 'cosine', sample_size = 10000))\n",
    "\n",
    "#joblib.dump(km, '120_cluster_lsa.pkl')\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tdidf_vectorizer.get_feature_names()\n",
    "for i in range(num_cluster):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :30]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Solution:\n",
    "    \"\"\"\n",
    "    @param s: A string\n",
    "    @return: Whether the string is a valid palindrome\n",
    "    \"\"\"\n",
    "    def isPalindrome(self, s):\n",
    "        # write your code here\n",
    "        if len(self.s) == 0:\n",
    "            return 'yes'\n",
    "        else:\n",
    "            new_str = ''.join(char for alph in self.s if char.isalnum())\n",
    "            for a in len(new_str):\n",
    "                if a == new_str.pop():\n",
    "                    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = ['a', 'b', 'c', 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isPalindrome( s):\n",
    "        # write your code here\n",
    "        if len(s) == 0:\n",
    "            return True\n",
    "        else:\n",
    "            new = ''.join(alph.lower() for alph in s if alph.isalnum())\n",
    "            for a in range(len(new)//2):\n",
    "                if new[a] == new[-(a+1)]:\n",
    "                    a += 1\n",
    "                else:\n",
    "                    return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isPalindrome(\"A man, a plan, a canal: Panama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern = \"aacacagt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prefix(pattern):\n",
    "    M = len(pattern)\n",
    "    lps = [0] * M\n",
    "    i = 1 ## initiate the first row of the prefix table index\n",
    "    j = 0 ## initiate the previous longest prefix\n",
    "    \n",
    "    while i < M:\n",
    "        if pattern[i] == pattern[j]:\n",
    "            j += 1\n",
    "            lps[i] = j\n",
    "            i += 1\n",
    "        else:\n",
    "            if j != 0:\n",
    "                j = lps[j-1]\n",
    "            else:\n",
    "                lps[i] = 0 \n",
    "                i += 1\n",
    "    return lps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prefix(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KMPSearch(pat, txt):\n",
    "    M = len(pat)\n",
    "    N = len(txt)\n",
    "    i = 0 # index for pat[]\n",
    "    j = 0 # index for txt[]\n",
    "    \n",
    "    lps = prefix(pat)\n",
    "    \n",
    "    while j < M:\n",
    "        if pat[i] == txt[j]: # if match\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif j < N and pat[i] != txt[j]:\n",
    "                if i != 0:\n",
    "                    i = lps[i-1] # move n steps according to the prefix table, and assin to the new i\n",
    "                else:\n",
    "                    i += 1 # if lps[i] = 0, it can only move to the right by 1\n",
    "        elif i == M:\n",
    "            print (\"Pattern Found at index \", str(j-i))\n",
    "            i = lps[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt = 'sdfaacacagt'\n",
    "pat = 'ac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def naiveSearch(pat, txt):\n",
    "    M = len(pat)\n",
    "    N = len(txt)\n",
    "    \n",
    "    for s in range(0, N-M+1):\n",
    "        if pat == txt[s:M+s]:\n",
    "            print ('Found', s)\n",
    "            break\n",
    "        else:\n",
    "            s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naiveSearch(pat, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in range(4, 0, -1):\n",
    "    print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
